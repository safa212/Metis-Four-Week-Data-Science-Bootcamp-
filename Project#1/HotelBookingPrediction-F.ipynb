{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Hotel Demands and Bookings Cancellation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hotels booking cancelation make it harder to accurately forecast and optimize\n",
    "occupancy which in turn results in revenue loss. The goal of this project is to\n",
    "predict in advance weather a hotel customer will cancel his booking or not.\n",
    "Predicting future booking cancellation can help hotels plan for cancellation and\n",
    "refund policies, staffing schedules as well as targeting customers with offers and\n",
    "discounts. It is also important to understand key booking cancellation factors and\n",
    "how those factors relate to booking cancellation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold,cross_validate \n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc\n",
    "#from pycaret.classification import *,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used \"Hotel booking demand” dataset available on Kaggle(https://www.kaggle.com/jessemostipak/hotel-booking-demand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booking = pd.read_csv('hotel_bookings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119390, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booking.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>...</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>737</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hotel  is_canceled  lead_time  arrival_date_year arrival_date_month  \\\n",
       "0  Resort Hotel            0        342               2015               July   \n",
       "1  Resort Hotel            0        737               2015               July   \n",
       "2  Resort Hotel            0          7               2015               July   \n",
       "3  Resort Hotel            0         13               2015               July   \n",
       "4  Resort Hotel            0         14               2015               July   \n",
       "\n",
       "   arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                        27                          1   \n",
       "1                        27                          1   \n",
       "2                        27                          1   \n",
       "3                        27                          1   \n",
       "4                        27                          1   \n",
       "\n",
       "   stays_in_weekend_nights  stays_in_week_nights  adults  ...  deposit_type  \\\n",
       "0                        0                     0       2  ...    No Deposit   \n",
       "1                        0                     0       2  ...    No Deposit   \n",
       "2                        0                     1       1  ...    No Deposit   \n",
       "3                        0                     1       1  ...    No Deposit   \n",
       "4                        0                     2       2  ...    No Deposit   \n",
       "\n",
       "   agent company days_in_waiting_list customer_type   adr  \\\n",
       "0    NaN     NaN                    0     Transient   0.0   \n",
       "1    NaN     NaN                    0     Transient   0.0   \n",
       "2    NaN     NaN                    0     Transient  75.0   \n",
       "3  304.0     NaN                    0     Transient  75.0   \n",
       "4  240.0     NaN                    0     Transient  98.0   \n",
       "\n",
       "   required_car_parking_spaces  total_of_special_requests  reservation_status  \\\n",
       "0                            0                          0           Check-Out   \n",
       "1                            0                          0           Check-Out   \n",
       "2                            0                          0           Check-Out   \n",
       "3                            0                          0           Check-Out   \n",
       "4                            0                          1           Check-Out   \n",
       "\n",
       "  reservation_status_date  \n",
       "0              2015-07-01  \n",
       "1              2015-07-01  \n",
       "2              2015-07-02  \n",
       "3              2015-07-02  \n",
       "4              2015-07-03  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hotel', 'is_canceled', 'lead_time', 'arrival_date_year',\n",
       "       'arrival_date_month', 'arrival_date_week_number',\n",
       "       'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
       "       'stays_in_week_nights', 'adults', 'children', 'babies', 'meal',\n",
       "       'country', 'market_segment', 'distribution_channel',\n",
       "       'is_repeated_guest', 'previous_cancellations',\n",
       "       'previous_bookings_not_canceled', 'reserved_room_type',\n",
       "       'assigned_room_type', 'booking_changes', 'deposit_type', 'agent',\n",
       "       'company', 'days_in_waiting_list', 'customer_type', 'adr',\n",
       "       'required_car_parking_spaces', 'total_of_special_requests',\n",
       "       'reservation_status', 'reservation_status_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booking.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 119,390 observations with 32 features. The individual\n",
    "sample/unit of analysis in this project is a single booking made by a hotel\n",
    "customer. There are 32 features related to the booking, including booking date,\n",
    "lead time, number of adults, children, babes, deposit type and previous\n",
    "cancellations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change columns order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['is_canceled','hotel','lead_time', 'arrival_date_year',\n",
    "       'arrival_date_month', 'arrival_date_week_number',\n",
    "       'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
    "       'stays_in_week_nights', 'adults', 'children', 'babies', 'meal',\n",
    "       'country', 'market_segment', 'distribution_channel',\n",
    "       'is_repeated_guest', 'previous_cancellations',\n",
    "       'previous_bookings_not_canceled', 'reserved_room_type',\n",
    "       'assigned_room_type', 'booking_changes', 'deposit_type', 'agent',\n",
    "       'company', 'days_in_waiting_list', 'customer_type', 'adr',\n",
    "       'required_car_parking_spaces', 'total_of_special_requests',\n",
    "       'reservation_status', 'reservation_status_date']\n",
    "df_booking=df_booking[cols] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "#profile = ProfileReport(df_booking)\n",
    "#profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Exploring the Null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_canceled</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>0.370416</td>\n",
       "      <td>0.482918</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_time</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>104.011416</td>\n",
       "      <td>106.863097</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>69.000</td>\n",
       "      <td>160.0</td>\n",
       "      <td>737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date_year</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>2016.156554</td>\n",
       "      <td>0.707476</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>2016.000</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>27.165173</td>\n",
       "      <td>13.605138</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>28.000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>15.798241</td>\n",
       "      <td>8.780829</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>16.000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>0.927599</td>\n",
       "      <td>0.998613</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>2.500302</td>\n",
       "      <td>1.908286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adults</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>1.856403</td>\n",
       "      <td>0.579261</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>119386.0</td>\n",
       "      <td>0.103890</td>\n",
       "      <td>0.398561</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babies</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.097436</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_repeated_guest</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>0.031912</td>\n",
       "      <td>0.175767</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous_cancellations</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>0.087118</td>\n",
       "      <td>0.844336</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous_bookings_not_canceled</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>1.497437</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>booking_changes</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>0.221124</td>\n",
       "      <td>0.652306</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agent</th>\n",
       "      <td>103050.0</td>\n",
       "      <td>86.693382</td>\n",
       "      <td>110.774548</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>14.000</td>\n",
       "      <td>229.0</td>\n",
       "      <td>535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>6797.0</td>\n",
       "      <td>189.266735</td>\n",
       "      <td>131.655015</td>\n",
       "      <td>6.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>179.000</td>\n",
       "      <td>270.0</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>2.321149</td>\n",
       "      <td>17.594721</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adr</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>101.831122</td>\n",
       "      <td>50.535790</td>\n",
       "      <td>-6.38</td>\n",
       "      <td>69.29</td>\n",
       "      <td>94.575</td>\n",
       "      <td>126.0</td>\n",
       "      <td>5400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>0.062518</td>\n",
       "      <td>0.245291</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <td>119390.0</td>\n",
       "      <td>0.571363</td>\n",
       "      <td>0.792798</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   count         mean         std      min  \\\n",
       "is_canceled                     119390.0     0.370416    0.482918     0.00   \n",
       "lead_time                       119390.0   104.011416  106.863097     0.00   \n",
       "arrival_date_year               119390.0  2016.156554    0.707476  2015.00   \n",
       "arrival_date_week_number        119390.0    27.165173   13.605138     1.00   \n",
       "arrival_date_day_of_month       119390.0    15.798241    8.780829     1.00   \n",
       "stays_in_weekend_nights         119390.0     0.927599    0.998613     0.00   \n",
       "stays_in_week_nights            119390.0     2.500302    1.908286     0.00   \n",
       "adults                          119390.0     1.856403    0.579261     0.00   \n",
       "children                        119386.0     0.103890    0.398561     0.00   \n",
       "babies                          119390.0     0.007949    0.097436     0.00   \n",
       "is_repeated_guest               119390.0     0.031912    0.175767     0.00   \n",
       "previous_cancellations          119390.0     0.087118    0.844336     0.00   \n",
       "previous_bookings_not_canceled  119390.0     0.137097    1.497437     0.00   \n",
       "booking_changes                 119390.0     0.221124    0.652306     0.00   \n",
       "agent                           103050.0    86.693382  110.774548     1.00   \n",
       "company                           6797.0   189.266735  131.655015     6.00   \n",
       "days_in_waiting_list            119390.0     2.321149   17.594721     0.00   \n",
       "adr                             119390.0   101.831122   50.535790    -6.38   \n",
       "required_car_parking_spaces     119390.0     0.062518    0.245291     0.00   \n",
       "total_of_special_requests       119390.0     0.571363    0.792798     0.00   \n",
       "\n",
       "                                    25%       50%     75%     max  \n",
       "is_canceled                        0.00     0.000     1.0     1.0  \n",
       "lead_time                         18.00    69.000   160.0   737.0  \n",
       "arrival_date_year               2016.00  2016.000  2017.0  2017.0  \n",
       "arrival_date_week_number          16.00    28.000    38.0    53.0  \n",
       "arrival_date_day_of_month          8.00    16.000    23.0    31.0  \n",
       "stays_in_weekend_nights            0.00     1.000     2.0    19.0  \n",
       "stays_in_week_nights               1.00     2.000     3.0    50.0  \n",
       "adults                             2.00     2.000     2.0    55.0  \n",
       "children                           0.00     0.000     0.0    10.0  \n",
       "babies                             0.00     0.000     0.0    10.0  \n",
       "is_repeated_guest                  0.00     0.000     0.0     1.0  \n",
       "previous_cancellations             0.00     0.000     0.0    26.0  \n",
       "previous_bookings_not_canceled     0.00     0.000     0.0    72.0  \n",
       "booking_changes                    0.00     0.000     0.0    21.0  \n",
       "agent                              9.00    14.000   229.0   535.0  \n",
       "company                           62.00   179.000   270.0   543.0  \n",
       "days_in_waiting_list               0.00     0.000     0.0   391.0  \n",
       "adr                               69.29    94.575   126.0  5400.0  \n",
       "required_car_parking_spaces        0.00     0.000     0.0     8.0  \n",
       "total_of_special_requests          0.00     0.000     1.0     5.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booking.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can see that adr has an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Detecting outliers in adr')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.boxplot(df_booking['adr'])\n",
    "plt.title(\"Detecting outliers in adr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df_booking[df_booking['adr']>1000].adr=df_booking['adr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booking.loc[df_booking['adr'] > 1000, 'adr'] = df_booking['adr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>hotel</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>...</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [is_canceled, hotel, lead_time, arrival_date_year, arrival_date_month, arrival_date_week_number, arrival_date_day_of_month, stays_in_weekend_nights, stays_in_week_nights, adults, children, babies, meal, country, market_segment, distribution_channel, is_repeated_guest, previous_cancellations, previous_bookings_not_canceled, reserved_room_type, assigned_room_type, booking_changes, deposit_type, agent, company, days_in_waiting_list, customer_type, adr, required_car_parking_spaces, total_of_special_requests, reservation_status, reservation_status_date]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booking[df_booking['adr']>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Detecting outliers in adr')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.boxplot(df_booking['adr'])\n",
    "plt.title(\"Detecting outliers in adr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119390 entries, 0 to 119389\n",
      "Data columns (total 32 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   is_canceled                     119390 non-null  int64  \n",
      " 1   hotel                           119390 non-null  object \n",
      " 2   lead_time                       119390 non-null  int64  \n",
      " 3   arrival_date_year               119390 non-null  int64  \n",
      " 4   arrival_date_month              119390 non-null  object \n",
      " 5   arrival_date_week_number        119390 non-null  int64  \n",
      " 6   arrival_date_day_of_month       119390 non-null  int64  \n",
      " 7   stays_in_weekend_nights         119390 non-null  int64  \n",
      " 8   stays_in_week_nights            119390 non-null  int64  \n",
      " 9   adults                          119390 non-null  int64  \n",
      " 10  children                        119386 non-null  float64\n",
      " 11  babies                          119390 non-null  int64  \n",
      " 12  meal                            119390 non-null  object \n",
      " 13  country                         118902 non-null  object \n",
      " 14  market_segment                  119390 non-null  object \n",
      " 15  distribution_channel            119390 non-null  object \n",
      " 16  is_repeated_guest               119390 non-null  int64  \n",
      " 17  previous_cancellations          119390 non-null  int64  \n",
      " 18  previous_bookings_not_canceled  119390 non-null  int64  \n",
      " 19  reserved_room_type              119390 non-null  object \n",
      " 20  assigned_room_type              119390 non-null  object \n",
      " 21  booking_changes                 119390 non-null  int64  \n",
      " 22  deposit_type                    119390 non-null  object \n",
      " 23  agent                           103050 non-null  float64\n",
      " 24  company                         6797 non-null    float64\n",
      " 25  days_in_waiting_list            119390 non-null  int64  \n",
      " 26  customer_type                   119390 non-null  object \n",
      " 27  adr                             119390 non-null  float64\n",
      " 28  required_car_parking_spaces     119390 non-null  int64  \n",
      " 29  total_of_special_requests       119390 non-null  int64  \n",
      " 30  reservation_status              119390 non-null  object \n",
      " 31  reservation_status_date         119390 non-null  object \n",
      "dtypes: float64(4), int64(16), object(12)\n",
      "memory usage: 29.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_booking.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Columns having missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>112593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agent</th>\n",
       "      <td>16340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reserved_room_type</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "company             112593\n",
       "agent                16340\n",
       "country                488\n",
       "children                 4\n",
       "reserved_room_type       0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls \n",
    " \n",
    "print (\"Top Columns having missing values\") \n",
    " \n",
    "missmap = df_booking.isnull().sum().to_frame() \n",
    "missmap = missmap.sort_values(0, ascending = False) \n",
    "missmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the company column as it is dominated by Null values\n",
    "df_booking.drop(columns=['company'],axis=1, inplace=True)\n",
    "\n",
    "# drop the raws with missing children values (only 4 raws)\n",
    "df_booking.dropna(subset=['children'], inplace=True)\n",
    "\n",
    "df_booking['country'].replace(np.nan,df_booking['country'].mode().values[0], inplace=True)\n",
    "\n",
    "# try non-existing value\n",
    "df_booking['agent'].replace(np.nan,df_booking['agent'].max(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Columns having missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_canceled</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_repeated_guest</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reservation_status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "is_canceled                  0\n",
       "is_repeated_guest            0\n",
       "reservation_status           0\n",
       "total_of_special_requests    0\n",
       "required_car_parking_spaces  0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls \n",
    " \n",
    "print (\"Top Columns having missing values\") \n",
    " \n",
    "missmap = df_booking.isnull().sum().to_frame() \n",
    "missmap = missmap.sort_values(0, ascending = False) \n",
    "missmap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring  data types  and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_canceled Possible Values:[0 1]\n",
      "hotel Possible Values:['Resort Hotel' 'City Hotel']\n",
      "lead_time Possible Values:[342 737   7  13  14   0   9  85  75  23  35  68  18  37  12  72 127  78\n",
      "  48  60  77  99 118  95  96  69  45  40  15  36  43  70  16 107  47 113\n",
      "  90  50  93  76   3   1  10   5  17  51  71  63  62 101   2  81 368 364\n",
      " 324  79  21 109 102   4  98  92  26  73 115  86  52  29  30  33  32   8\n",
      " 100  44  80  97  64  39  34  27  82  94 110 111  84  66 104  28 258 112\n",
      "  65  67  55  88  54 292  83 105 280 394  24 103 366 249  22  91  11 108\n",
      " 106  31  87  41 304 117  59  53  58 116  42 321  38  56  49 317   6  57\n",
      "  19  25 315 123  46  89  61 312 299 130  74 298 119  20 286 136 129 124\n",
      " 327 131 460 140 114 139 122 137 126 120 128 135 150 143 151 132 125 157\n",
      " 147 138 156 164 346 159 160 161 333 381 149 154 297 163 314 155 323 340\n",
      " 356 142 328 144 336 248 302 175 344 382 146 170 166 338 167 310 148 165\n",
      " 172 171 145 121 178 305 173 152 354 347 158 185 349 183 352 177 200 192\n",
      " 361 207 174 330 134 350 334 283 153 197 133 241 193 235 194 261 260 216\n",
      " 169 209 238 215 141 189 187 223 284 214 202 211 168 230 203 188 232 709\n",
      " 219 162 196 190 259 228 176 250 201 186 199 180 206 205 224 222 182 210\n",
      " 275 212 229 218 208 191 181 179 246 255 226 288 253 252 262 236 256 234\n",
      " 254 468 213 237 198 195 239 263 265 274 217 220 307 221 233 257 227 276\n",
      " 225 264 311 277 204 290 266 270 294 319 282 251 322 291 269 240 271 184\n",
      " 231 268 247 273 300 301 267 244 306 293 309 272 242 295 285 243 308 398\n",
      " 303 245 424 279 331 281 339 434 357 325 329 278 332 343 345 360 348 367\n",
      " 353 373 374 406 400 326 379 399 316 341 320 385 355 363 358 296 422 390\n",
      " 335 370 376 375 397 289 542 403 383 384 359 393 337 362 365 435 386 378\n",
      " 313 351 287 471 462 411 450 318 372 371 454 532 445 389 388 407 443 437\n",
      " 451 391 405 412 419 420 426 433 440 429 418 447 461 605 457 475 464 482\n",
      " 626 489 496 503 510 517 524 531 538 545 552 559 566 573 580 587 594 601\n",
      " 608 615 622 629 396 410 395 423 408 409 448 465 387 414 476 479 467 490\n",
      " 493 478 504 507 458 518 521 377 444 380 463]\n",
      "arrival_date_year Possible Values:[2015 2016 2017]\n",
      "arrival_date_month Possible Values:['July' 'August' 'September' 'October' 'November' 'December' 'January'\n",
      " 'February' 'March' 'April' 'May' 'June']\n",
      "arrival_date_week_number Possible Values:[27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 51 52 53  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21\n",
      " 22 23 24 25 26]\n",
      "arrival_date_day_of_month Possible Values:[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31]\n",
      "stays_in_weekend_nights Possible Values:[ 0  1  2  4  3  6 13  8  5  7 12  9 16 18 19 10 14]\n",
      "stays_in_week_nights Possible Values:[ 0  1  2  3  4  5 10 11  8  6  7 15  9 12 33 20 14 16 21 13 30 19 24 40\n",
      " 22 42 50 25 17 32 26 18 34 35 41]\n",
      "adults Possible Values:[ 2  1  3  4 40 26 50 27 55  0 20  6  5 10]\n",
      "children Possible Values:[ 0.  1.  2. 10.  3.]\n",
      "babies Possible Values:[ 0  1  2 10  9]\n",
      "meal Possible Values:['BB' 'FB' 'HB' 'SC' 'Undefined']\n",
      "country Possible Values:['PRT' 'GBR' 'USA' 'ESP' 'IRL' 'FRA' 'ROU' 'NOR' 'OMN' 'ARG' 'POL' 'DEU'\n",
      " 'BEL' 'CHE' 'CN' 'GRC' 'ITA' 'NLD' 'DNK' 'RUS' 'SWE' 'AUS' 'EST' 'CZE'\n",
      " 'BRA' 'FIN' 'MOZ' 'BWA' 'LUX' 'SVN' 'ALB' 'IND' 'CHN' 'MEX' 'MAR' 'UKR'\n",
      " 'SMR' 'LVA' 'PRI' 'SRB' 'CHL' 'AUT' 'BLR' 'LTU' 'TUR' 'ZAF' 'AGO' 'ISR'\n",
      " 'CYM' 'ZMB' 'CPV' 'ZWE' 'DZA' 'KOR' 'CRI' 'HUN' 'ARE' 'TUN' 'JAM' 'HRV'\n",
      " 'HKG' 'IRN' 'GEO' 'AND' 'GIB' 'URY' 'JEY' 'CAF' 'CYP' 'COL' 'GGY' 'KWT'\n",
      " 'NGA' 'MDV' 'VEN' 'SVK' 'FJI' 'KAZ' 'PAK' 'IDN' 'LBN' 'PHL' 'SEN' 'SYC'\n",
      " 'AZE' 'BHR' 'NZL' 'THA' 'DOM' 'MKD' 'MYS' 'ARM' 'JPN' 'LKA' 'CUB' 'CMR'\n",
      " 'BIH' 'MUS' 'COM' 'SUR' 'UGA' 'BGR' 'CIV' 'JOR' 'SYR' 'SGP' 'BDI' 'SAU'\n",
      " 'VNM' 'PLW' 'QAT' 'EGY' 'PER' 'MLT' 'MWI' 'ECU' 'MDG' 'ISL' 'UZB' 'NPL'\n",
      " 'BHS' 'MAC' 'TGO' 'TWN' 'DJI' 'STP' 'KNA' 'ETH' 'IRQ' 'HND' 'RWA' 'KHM'\n",
      " 'MCO' 'BGD' 'IMN' 'TJK' 'NIC' 'BEN' 'VGB' 'TZA' 'GAB' 'GHA' 'TMP' 'GLP'\n",
      " 'KEN' 'LIE' 'GNB' 'MNE' 'UMI' 'MYT' 'FRO' 'MMR' 'PAN' 'BFA' 'LBY' 'MLI'\n",
      " 'NAM' 'BOL' 'PRY' 'BRB' 'ABW' 'AIA' 'SLV' 'DMA' 'PYF' 'GUY' 'LCA' 'ATA'\n",
      " 'GTM' 'ASM' 'MRT' 'NCL' 'KIR' 'SDN' 'ATF' 'SLE' 'LAO']\n",
      "market_segment Possible Values:['Direct' 'Corporate' 'Online TA' 'Offline TA/TO' 'Complementary' 'Groups'\n",
      " 'Aviation']\n",
      "distribution_channel Possible Values:['Direct' 'Corporate' 'TA/TO' 'Undefined' 'GDS']\n",
      "is_repeated_guest Possible Values:[0 1]\n",
      "previous_cancellations Possible Values:[ 0  1  2  3 26 25 14  4 24 19  5 21  6 13 11]\n",
      "previous_bookings_not_canceled Possible Values:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 24\n",
      " 25 27 28 29 30 19 26 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72]\n",
      "reserved_room_type Possible Values:['C' 'A' 'D' 'E' 'G' 'F' 'H' 'L' 'P' 'B']\n",
      "assigned_room_type Possible Values:['C' 'A' 'D' 'E' 'G' 'F' 'I' 'B' 'H' 'P' 'L' 'K']\n",
      "booking_changes Possible Values:[ 3  4  0  1  2  5 17  6  8  7 10 16  9 13 12 20 14 15 11 21 18]\n",
      "deposit_type Possible Values:['No Deposit' 'Refundable' 'Non Refund']\n",
      "agent Possible Values:[535. 304. 240. 303.  15. 241.   8. 250. 115.   5. 175. 134. 156. 243.\n",
      " 242.   3. 105.  40. 147. 306. 184.  96.   2. 127.  95. 146.   9. 177.\n",
      "   6. 143. 244. 149. 167. 300. 171. 305.  67. 196. 152. 142. 261. 104.\n",
      "  36.  26.  29. 258. 110.  71. 181.  88. 251. 275.  69. 248. 208. 256.\n",
      " 314. 126. 281. 273. 253. 185. 330. 334. 328. 326. 321. 324. 313.  38.\n",
      " 155.  68. 335. 308. 332.  94. 348. 310. 339. 375.  66. 327. 387. 298.\n",
      "  91. 245. 385. 257. 393. 168. 405. 249. 315.  75. 128. 307.  11. 436.\n",
      "   1. 201. 183. 223. 368. 336. 291. 464. 411. 481.  10. 154. 468. 410.\n",
      " 390. 440. 495. 492. 493. 434.  57. 531. 420. 483. 526. 472. 429.  16.\n",
      " 446.  34.  78. 139. 252. 270.  47. 114. 301. 193. 182. 135. 350. 195.\n",
      " 352. 355. 159. 363. 384. 360. 331. 367.  64. 406. 163. 414. 333. 427.\n",
      " 431. 430. 426. 438. 433. 418. 441. 282. 432.  72. 450. 180. 454. 455.\n",
      "  59. 451. 254. 358. 469. 165. 467. 510. 337. 476. 502. 527. 479. 508.\n",
      " 302. 497. 187.  13.   7.  27.  14.  22.  17.  28.  42.  20.  19.  45.\n",
      "  37.  61.  39.  21.  24.  41.  50.  30.  54.  52.  12.  44.  31.  83.\n",
      "  32.  63.  60.  55.  56.  89.  87. 118.  86.  85. 210. 214. 129. 179.\n",
      " 138. 174. 170. 153.  93. 151. 119.  35. 173.  58.  53. 133.  79. 235.\n",
      " 192. 191. 236. 162. 215. 157. 287. 132. 234.  98.  77. 103. 107. 262.\n",
      " 220. 121. 205. 378.  23. 296. 290. 229.  33. 286. 276. 425. 484. 323.\n",
      " 403. 219. 394. 509. 111. 423.   4.  70.  82.  81.  74.  92.  99.  90.\n",
      " 112. 117. 106. 148. 158. 144. 211. 213. 216. 232. 150. 267. 227. 247.\n",
      " 278. 280. 285. 289. 269. 295. 265. 288. 122. 294. 325. 341. 344. 346.\n",
      " 359. 283. 364. 370. 371.  25. 141. 391. 397. 416. 404. 299. 197.  73.\n",
      " 354. 444. 408. 461. 388. 453. 459. 474. 475. 480. 449.]\n",
      "days_in_waiting_list Possible Values:[  0  50  47  65 122  75 101 150 125  14  60  34 100  22 121  61  39   5\n",
      "   1   8 107  43  52   2  11 142 116  13  44  97  83   4 113  18  20 185\n",
      "  93 109   6  37 105 154  64  99  38  48  33  77  21  80  59  40  58  89\n",
      "  53  49  69  87  91  57 111  79  98  85  63  15   3  41 224  31  56 187\n",
      " 176  71  55  96 236 259 207 215 160 120  30  32  27  62  24 108 147 379\n",
      "  70  35 178 330 223 174 162 391  68 193  10  76  16  28   9 165  17  25\n",
      "  46   7  84 175 183  23 117  12  54  26  73  45  19  42  72  81  92  74\n",
      " 167  36]\n",
      "customer_type Possible Values:['Transient' 'Contract' 'Transient-Party' 'Group']\n",
      "adr Possible Values:[  0.    75.    98.   ... 266.75 209.25 157.71]\n",
      "required_car_parking_spaces Possible Values:[0 1 2 8 3]\n",
      "total_of_special_requests Possible Values:[0 1 3 2 4 5]\n",
      "reservation_status Possible Values:['Check-Out' 'Canceled' 'No-Show']\n",
      "reservation_status_date Possible Values:['2015-07-01' '2015-07-02' '2015-07-03' '2015-05-06' '2015-04-22'\n",
      " '2015-06-23' '2015-07-05' '2015-07-06' '2015-07-07' '2015-07-08'\n",
      " '2015-05-11' '2015-07-15' '2015-07-16' '2015-05-29' '2015-05-19'\n",
      " '2015-06-19' '2015-05-23' '2015-05-18' '2015-07-09' '2015-06-02'\n",
      " '2015-07-13' '2015-07-04' '2015-06-29' '2015-06-16' '2015-06-18'\n",
      " '2015-06-12' '2015-06-09' '2015-05-26' '2015-07-11' '2015-07-12'\n",
      " '2015-07-17' '2015-04-15' '2015-05-13' '2015-07-10' '2015-05-20'\n",
      " '2015-05-12' '2015-07-14' '2015-06-17' '2015-05-01' '2015-03-30'\n",
      " '2015-07-19' '2015-06-03' '2015-06-26' '2015-05-14' '2015-07-20'\n",
      " '2015-05-07' '2015-05-28' '2015-04-13' '2015-03-25' '2015-07-21'\n",
      " '2015-06-27' '2015-07-18' '2015-07-23' '2015-06-08' '2015-06-22'\n",
      " '2015-06-24' '2015-03-05' '2015-06-01' '2015-04-24' '2015-07-22'\n",
      " '2015-05-27' '2015-04-06' '2015-04-11' '2015-07-25' '2015-07-28'\n",
      " '2015-07-29' '2015-06-25' '2015-07-24' '2015-06-05' '2015-06-30'\n",
      " '2015-06-13' '2015-06-11' '2015-07-30' '2015-07-27' '2015-04-29'\n",
      " '2015-06-04' '2015-07-26' '2015-08-01' '2015-08-02' '2015-06-15'\n",
      " '2015-04-23' '2015-07-31' '2015-05-25' '2015-08-03' '2015-04-17'\n",
      " '2015-08-04' '2015-08-06' '2015-05-15' '2015-05-09' '2015-03-17'\n",
      " '2015-05-22' '2015-08-07' '2015-04-04' '2015-08-05' '2015-08-08'\n",
      " '2015-08-10' '2015-05-04' '2015-06-06' '2015-08-09' '2015-08-15'\n",
      " '2015-08-11' '2015-03-28' '2015-08-14' '2015-08-12' '2015-08-16'\n",
      " '2015-05-16' '2015-08-21' '2015-08-13' '2015-08-17' '2015-04-20'\n",
      " '2015-08-18' '2015-08-23' '2015-08-22' '2015-08-19' '2015-08-20'\n",
      " '2015-08-29' '2015-03-31' '2015-05-30' '2015-08-25' '2015-04-14'\n",
      " '2015-08-24' '2015-03-24' '2015-05-21' '2015-08-28' '2015-08-26'\n",
      " '2015-08-27' '2015-08-30' '2015-08-31' '2015-09-06' '2015-09-03'\n",
      " '2015-09-04' '2015-09-02' '2015-09-01' '2015-09-05' '2015-06-20'\n",
      " '2015-09-07' '2015-09-10' '2015-09-11' '2015-09-08' '2015-09-09'\n",
      " '2015-09-13' '2015-09-15' '2015-04-10' '2015-01-02' '2014-11-18'\n",
      " '2015-09-12' '2015-09-17' '2015-09-14' '2015-04-07' '2015-09-19'\n",
      " '2015-09-16' '2015-09-20' '2015-01-18' '2015-10-23' '2015-01-22'\n",
      " '2015-01-01' '2015-09-22' '2015-09-24' '2015-09-18' '2015-09-21'\n",
      " '2015-09-30' '2015-09-25' '2015-09-27' '2015-09-28' '2015-10-12'\n",
      " '2015-09-29' '2015-09-23' '2015-10-01' '2015-09-26' '2015-04-18'\n",
      " '2015-10-02' '2015-10-04' '2015-10-08' '2015-10-03' '2015-10-07'\n",
      " '2015-10-09' '2015-10-11' '2015-10-05' '2015-10-06' '2015-10-10'\n",
      " '2015-10-14' '2015-10-15' '2015-10-18' '2015-10-13' '2015-10-20'\n",
      " '2015-10-19' '2015-10-31' '2015-10-16' '2015-10-21' '2015-10-22'\n",
      " '2015-10-17' '2015-10-24' '2015-10-25' '2015-10-28' '2015-10-27'\n",
      " '2015-10-26' '2015-10-30' '2015-11-05' '2015-10-29' '2015-11-03'\n",
      " '2015-11-07' '2015-11-04' '2015-11-01' '2015-11-02' '2015-11-17'\n",
      " '2015-11-06' '2015-11-10' '2015-11-08' '2015-11-09' '2015-11-15'\n",
      " '2015-11-16' '2015-11-11' '2015-11-12' '2015-11-14' '2015-11-13'\n",
      " '2015-11-18' '2015-11-22' '2015-11-19' '2015-11-21' '2015-11-20'\n",
      " '2015-11-24' '2015-11-25' '2015-11-23' '2015-11-28' '2015-11-26'\n",
      " '2015-11-27' '2015-11-29' '2015-12-04' '2015-12-01' '2015-12-06'\n",
      " '2015-12-08' '2015-12-02' '2015-12-03' '2015-12-31' '2015-12-05'\n",
      " '2015-12-10' '2015-12-17' '2015-11-30' '2015-12-12' '2015-12-07'\n",
      " '2016-01-05' '2015-12-11' '2015-12-13' '2015-12-15' '2015-12-16'\n",
      " '2015-12-19' '2015-12-18' '2015-12-26' '2015-12-27' '2015-12-22'\n",
      " '2015-12-23' '2015-12-24' '2015-12-29' '2015-12-28' '2015-12-20'\n",
      " '2015-12-30' '2016-01-02' '2016-01-01' '2015-12-25' '2016-01-03'\n",
      " '2016-01-04' '2016-01-11' '2016-01-07' '2015-12-21' '2016-01-09'\n",
      " '2016-01-10' '2016-01-08' '2016-01-06' '2016-01-12' '2016-01-13'\n",
      " '2016-01-23' '2016-02-09' '2016-01-15' '2016-01-16' '2016-01-17'\n",
      " '2016-01-19' '2016-01-18' '2016-01-21' '2016-01-24' '2016-01-22'\n",
      " '2016-01-29' '2016-01-27' '2016-01-25' '2016-03-08' '2016-01-26'\n",
      " '2016-01-20' '2016-01-30' '2016-02-01' '2016-02-02' '2016-02-08'\n",
      " '2016-02-07' '2016-01-28' '2016-02-05' '2016-02-03' '2016-02-13'\n",
      " '2016-02-10' '2016-02-04' '2016-02-12' '2016-02-11' '2016-02-16'\n",
      " '2016-02-14' '2016-02-15' '2016-02-20' '2016-02-06' '2016-01-14'\n",
      " '2016-02-17' '2016-02-21' '2016-02-24' '2016-02-25' '2016-02-19'\n",
      " '2016-02-18' '2016-02-26' '2016-02-23' '2016-03-05' '2016-02-22'\n",
      " '2016-02-27' '2016-03-03' '2016-03-24' '2016-03-04' '2016-02-29'\n",
      " '2016-03-01' '2016-03-02' '2016-03-30' '2016-03-07' '2016-03-14'\n",
      " '2016-03-21' '2016-03-09' '2016-03-12' '2016-03-22' '2016-03-10'\n",
      " '2016-03-11' '2016-03-20' '2016-03-15' '2016-03-17' '2016-03-16'\n",
      " '2016-03-19' '2016-03-27' '2016-03-18' '2016-03-26' '2016-03-31'\n",
      " '2016-03-28' '2016-03-29' '2016-04-01' '2016-03-23' '2016-04-02'\n",
      " '2016-03-25' '2016-03-13' '2016-04-04' '2016-04-03' '2016-04-05'\n",
      " '2016-04-08' '2016-04-06' '2016-04-09' '2016-04-12' '2016-04-16'\n",
      " '2016-04-17' '2016-04-27' '2016-04-14' '2016-04-18' '2016-04-21'\n",
      " '2016-04-19' '2016-04-20' '2016-04-10' '2016-04-13' '2016-04-11'\n",
      " '2016-04-07' '2016-04-15' '2016-04-22' '2016-04-23' '2016-04-26'\n",
      " '2016-04-28' '2016-04-24' '2016-04-25' '2016-04-29' '2016-04-30'\n",
      " '2016-05-01' '2016-05-10' '2016-05-02' '2016-05-07' '2016-05-08'\n",
      " '2016-05-12' '2016-05-04' '2016-05-06' '2016-05-03' '2016-05-09'\n",
      " '2016-05-05' '2016-05-13' '2016-05-14' '2016-05-18' '2016-05-19'\n",
      " '2016-05-15' '2016-05-16' '2016-05-11' '2016-05-21' '2016-05-22'\n",
      " '2016-05-20' '2016-05-24' '2016-05-25' '2016-05-26' '2016-05-23'\n",
      " '2016-05-27' '2016-05-17' '2016-05-29' '2016-05-28' '2016-05-30'\n",
      " '2016-05-31' '2016-06-01' '2016-06-03' '2016-06-08' '2016-06-02'\n",
      " '2016-06-05' '2016-06-06' '2016-06-13' '2016-06-07' '2016-06-10'\n",
      " '2016-06-11' '2016-06-16' '2016-06-12' '2016-06-14' '2016-06-17'\n",
      " '2016-06-04' '2016-06-18' '2016-06-21' '2016-06-09' '2016-06-24'\n",
      " '2016-06-20' '2016-06-25' '2016-06-22' '2016-06-26' '2016-06-23'\n",
      " '2016-07-01' '2016-06-15' '2016-06-28' '2016-07-02' '2016-06-19'\n",
      " '2016-06-27' '2016-07-04' '2016-06-30' '2016-07-05' '2016-07-08'\n",
      " '2016-07-09' '2016-07-07' '2016-07-12' '2016-06-29' '2016-07-10'\n",
      " '2016-07-15' '2016-07-03' '2016-07-16' '2016-07-14' '2016-07-18'\n",
      " '2016-07-13' '2016-07-06' '2016-07-20' '2016-07-21' '2016-07-23'\n",
      " '2016-07-19' '2016-07-11' '2016-07-28' '2016-07-17' '2016-07-25'\n",
      " '2016-07-22' '2016-07-29' '2016-08-03' '2016-08-02' '2016-08-04'\n",
      " '2016-08-08' '2016-08-10' '2016-08-01' '2016-08-06' '2016-03-06'\n",
      " '2016-08-05' '2016-07-26' '2016-08-07' '2016-07-30' '2016-07-24'\n",
      " '2016-08-12' '2016-07-27' '2016-08-13' '2016-08-18' '2016-08-16'\n",
      " '2016-08-15' '2016-08-17' '2016-08-11' '2016-07-31' '2016-08-19'\n",
      " '2016-09-01' '2016-08-23' '2016-08-26' '2016-08-20' '2016-08-21'\n",
      " '2016-09-04' '2016-08-22' '2016-08-27' '2016-08-25' '2016-08-09'\n",
      " '2016-09-05' '2016-08-24' '2016-09-10' '2016-08-29' '2016-09-09'\n",
      " '2016-08-30' '2016-09-13' '2016-08-31' '2016-09-14' '2016-09-12'\n",
      " '2016-09-15' '2016-08-14' '2016-09-02' '2016-09-08' '2016-09-19'\n",
      " '2016-09-16' '2016-09-07' '2016-09-21' '2016-09-06' '2016-09-22'\n",
      " '2016-09-17' '2016-09-20' '2016-09-03' '2016-09-26' '2016-09-23'\n",
      " '2016-09-18' '2016-09-29' '2016-10-02' '2016-10-01' '2016-09-27'\n",
      " '2016-09-25' '2016-10-05' '2016-09-11' '2016-09-30' '2016-10-09'\n",
      " '2016-10-03' '2016-10-06' '2016-10-11' '2016-09-24' '2016-10-13'\n",
      " '2016-09-28' '2016-10-08' '2016-10-07' '2016-10-16' '2016-08-28'\n",
      " '2016-10-17' '2016-10-18' '2016-10-10' '2016-10-04' '2016-10-15'\n",
      " '2016-10-19' '2016-10-21' '2016-10-12' '2016-10-24' '2016-10-26'\n",
      " '2016-10-23' '2016-10-20' '2016-10-25' '2016-10-27' '2016-10-28'\n",
      " '2016-10-30' '2016-10-29' '2016-11-01' '2016-11-04' '2016-10-14'\n",
      " '2016-11-07' '2016-11-03' '2016-11-10' '2016-11-14' '2016-11-02'\n",
      " '2016-10-31' '2016-11-11' '2016-11-08' '2016-11-05' '2016-11-25'\n",
      " '2016-11-09' '2016-11-20' '2016-11-21' '2016-10-22' '2016-11-22'\n",
      " '2016-11-16' '2016-11-23' '2016-11-17' '2016-11-06' '2016-11-15'\n",
      " '2016-11-13' '2016-11-12' '2016-11-27' '2016-11-19' '2016-11-30'\n",
      " '2016-11-18' '2016-12-02' '2016-12-04' '2016-11-29' '2016-12-07'\n",
      " '2016-11-28' '2016-12-03' '2016-12-06' '2016-11-24' '2016-12-08'\n",
      " '2016-12-05' '2016-12-10' '2016-12-13' '2016-12-14' '2016-12-16'\n",
      " '2016-12-15' '2016-12-17' '2016-12-19' '2016-12-21' '2016-12-20'\n",
      " '2016-12-22' '2016-12-23' '2016-12-24' '2016-12-01' '2016-12-27'\n",
      " '2016-12-29' '2016-12-30' '2016-12-12' '2017-01-02' '2016-12-11'\n",
      " '2017-01-03' '2017-01-04' '2017-01-01' '2016-12-26' '2017-01-06'\n",
      " '2016-12-28' '2016-12-18' '2017-01-10' '2017-01-11' '2017-01-07'\n",
      " '2017-01-12' '2017-01-16' '2017-01-14' '2017-01-13' '2017-01-05'\n",
      " '2017-01-17' '2017-01-20' '2016-12-09' '2017-01-26' '2016-12-31'\n",
      " '2017-01-23' '2017-01-27' '2017-01-28' '2017-01-19' '2017-01-25'\n",
      " '2017-01-24' '2017-01-29' '2017-01-18' '2016-12-25' '2017-01-15'\n",
      " '2017-01-21' '2017-02-01' '2017-02-02' '2017-01-31' '2017-02-03'\n",
      " '2017-02-04' '2017-02-06' '2017-02-07' '2017-02-08' '2017-01-30'\n",
      " '2017-02-09' '2017-01-09' '2017-02-11' '2017-02-10' '2017-02-12'\n",
      " '2017-02-13' '2017-02-14' '2017-02-16' '2017-02-17' '2017-02-18'\n",
      " '2017-02-19' '2017-02-20' '2017-02-15' '2017-02-21' '2017-02-22'\n",
      " '2017-02-26' '2017-02-23' '2017-02-24' '2017-02-25' '2017-02-28'\n",
      " '2017-03-05' '2017-02-27' '2017-03-03' '2017-03-06' '2017-03-02'\n",
      " '2017-03-08' '2017-03-09' '2017-03-10' '2017-03-07' '2017-03-12'\n",
      " '2017-03-13' '2017-03-14' '2017-03-01' '2017-03-18' '2017-03-17'\n",
      " '2017-03-24' '2017-03-22' '2017-03-26' '2017-03-27' '2017-03-11'\n",
      " '2017-03-28' '2017-03-29' '2017-03-30' '2017-03-31' '2017-03-19'\n",
      " '2017-01-22' '2017-04-02' '2017-03-20' '2017-04-03' '2017-01-08'\n",
      " '2017-03-23' '2017-04-05' '2017-02-05' '2017-04-04' '2017-03-15'\n",
      " '2017-04-07' '2017-03-25' '2017-04-08' '2017-04-06' '2017-03-21'\n",
      " '2017-04-10' '2017-04-01' '2017-04-11' '2017-04-13' '2017-04-15'\n",
      " '2017-04-12' '2017-03-04' '2017-04-19' '2017-04-22' '2017-04-20'\n",
      " '2017-05-02' '2017-04-09' '2017-04-23' '2017-04-24' '2017-04-16'\n",
      " '2017-04-28' '2017-04-18' '2017-04-26' '2017-04-25' '2017-04-17'\n",
      " '2017-04-21' '2017-05-03' '2017-05-04' '2017-03-16' '2017-05-05'\n",
      " '2017-04-29' '2017-04-14' '2017-05-08' '2017-04-27' '2017-05-11'\n",
      " '2017-05-01' '2017-05-10' '2017-05-13' '2017-05-06' '2017-05-14'\n",
      " '2017-05-16' '2017-04-30' '2017-05-15' '2017-05-07' '2017-05-09'\n",
      " '2017-05-17' '2017-05-21' '2017-05-12' '2017-05-22' '2017-05-24'\n",
      " '2017-05-23' '2017-05-25' '2017-05-26' '2017-05-28' '2017-05-27'\n",
      " '2017-05-29' '2017-05-19' '2017-05-31' '2017-05-20' '2017-06-01'\n",
      " '2017-05-30' '2017-06-02' '2016-11-26' '2017-06-04' '2017-06-05'\n",
      " '2017-06-06' '2017-06-07' '2017-05-18' '2017-06-09' '2017-06-10'\n",
      " '2017-06-11' '2017-06-12' '2017-06-14' '2017-06-08' '2017-06-16'\n",
      " '2017-06-13' '2017-06-03' '2017-06-24' '2017-06-20' '2017-06-19'\n",
      " '2017-06-21' '2017-06-26' '2017-06-27' '2017-06-22' '2017-06-28'\n",
      " '2017-06-15' '2017-06-29' '2017-06-30' '2017-06-18' '2017-07-04'\n",
      " '2017-07-08' '2017-07-05' '2017-07-03' '2017-07-07' '2017-07-01'\n",
      " '2017-07-06' '2017-07-11' '2017-07-12' '2017-06-23' '2017-07-13'\n",
      " '2017-07-02' '2017-07-10' '2017-07-14' '2017-07-15' '2017-07-16'\n",
      " '2017-07-18' '2017-07-17' '2017-07-19' '2017-07-20' '2017-07-21'\n",
      " '2017-06-25' '2017-06-17' '2017-07-24' '2017-07-26' '2017-07-09'\n",
      " '2017-07-27' '2017-07-28' '2017-07-31' '2017-07-29' '2017-07-22'\n",
      " '2017-08-02' '2017-08-01' '2017-08-03' '2017-08-04' '2017-07-25'\n",
      " '2017-07-23' '2017-08-09' '2017-08-10' '2017-07-30' '2017-08-07'\n",
      " '2017-08-13' '2017-08-05' '2017-08-14' '2017-08-08' '2017-08-16'\n",
      " '2017-08-17' '2017-08-15' '2017-08-18' '2017-08-20' '2017-08-22'\n",
      " '2017-08-06' '2017-08-25' '2017-08-26' '2017-08-23' '2017-08-11'\n",
      " '2017-08-27' '2017-08-21' '2017-08-29' '2017-08-31' '2017-08-12'\n",
      " '2017-08-19' '2016-01-31' '2017-09-01' '2017-08-28' '2015-04-03'\n",
      " '2015-01-21' '2015-01-28' '2015-01-29' '2015-01-30' '2015-02-02'\n",
      " '2015-02-05' '2015-02-06' '2015-02-09' '2015-02-10' '2015-02-11'\n",
      " '2015-02-12' '2015-02-19' '2015-02-20' '2015-02-23' '2015-02-24'\n",
      " '2015-02-25' '2015-02-26' '2015-02-27' '2015-03-03' '2015-03-04'\n",
      " '2015-03-06' '2015-03-09' '2015-03-11' '2015-03-12' '2015-03-18'\n",
      " '2015-04-02' '2015-06-14' '2015-04-08' '2015-04-16' '2015-04-25'\n",
      " '2015-04-28' '2015-05-08' '2017-09-06' '2016-02-28' '2015-12-09'\n",
      " '2015-12-14' '2017-09-09' '2017-09-02' '2017-08-24' '2017-08-30'\n",
      " '2017-09-03' '2017-09-04' '2017-09-05' '2017-09-07' '2017-09-08'\n",
      " '2017-09-10' '2017-09-12' '2017-09-14' '2015-04-30' '2015-04-21'\n",
      " '2015-04-05' '2015-03-13' '2015-05-05' '2015-03-29' '2015-06-10'\n",
      " '2015-04-27' '2014-10-17' '2015-01-20' '2015-02-17' '2015-03-10'\n",
      " '2015-03-23']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns=df_booking.columns\n",
    "\n",
    "for col in columns:\n",
    "    print('{} Possible Values:{}'.format(col,df_booking[col].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_canceled                         int64\n",
       "hotel                              object\n",
       "lead_time                           int64\n",
       "arrival_date_year                   int64\n",
       "arrival_date_month                 object\n",
       "arrival_date_week_number            int64\n",
       "arrival_date_day_of_month           int64\n",
       "stays_in_weekend_nights             int64\n",
       "stays_in_week_nights                int64\n",
       "adults                              int64\n",
       "children                          float64\n",
       "babies                              int64\n",
       "meal                               object\n",
       "country                            object\n",
       "market_segment                     object\n",
       "distribution_channel               object\n",
       "is_repeated_guest                   int64\n",
       "previous_cancellations              int64\n",
       "previous_bookings_not_canceled      int64\n",
       "reserved_room_type                 object\n",
       "assigned_room_type                 object\n",
       "booking_changes                     int64\n",
       "deposit_type                       object\n",
       "agent                             float64\n",
       "days_in_waiting_list                int64\n",
       "customer_type                      object\n",
       "adr                               float64\n",
       "required_car_parking_spaces         int64\n",
       "total_of_special_requests           int64\n",
       "reservation_status                 object\n",
       "reservation_status_date            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booking.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change type of arrival_date_month,children agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booking['arrival_date_month']=df_booking['arrival_date_month'].astype(str)\n",
    "\n",
    "df_booking['children']=df_booking['children'].astype(int)\n",
    "df_booking['agent']=df_booking['agent'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75166\n",
       "1    44220\n",
       "Name: is_canceled, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booking.is_canceled.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new booking_date Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the date and time fields into a single datetime column\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'year':df_booking.arrival_date_year,\n",
    "    'month': df_booking.arrival_date_month,\n",
    "    'day': df_booking.arrival_date_day_of_month\n",
    "})\n",
    "#df['month'] = pd.to_datetime(df.month, format='%B').dt.month\n",
    "#df_booking[\"booking_date\"] = pd.to_datetime(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_booking[\"booking_date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify hotel type with highest number of cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'hotel', data = df_booking, hue = 'is_canceled')\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservation Status by Hotel type\", weight='bold')\n",
    "plt.xlabel('Hotel type')\n",
    "plt.ylabel('Number of Reservation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify year with highest number of confirmation/cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'arrival_date_year', data = df_booking, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservation Status by Year\", weight='bold')\n",
    "plt.xlabel('Arrival Year')\n",
    "plt.ylabel('Number of Reservation')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify months with highest number of confirmation/cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'arrival_date_month', data = df_booking, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservation Status by Month\", weight='bold')\n",
    "plt.xlabel('Arrival Month')\n",
    "plt.ylabel('Number of Reservation')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_month=df_booking.groupby('arrival_date_month').count()\n",
    "booking_month=booking_month.iloc[:,[0]]\n",
    "\n",
    "canceled_month=df_booking.groupby('arrival_date_month').sum()\n",
    "canceled_month=canceled_month.iloc[:,[0]]\n",
    "\n",
    "booking_month=booking_month.reindex(['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'])\n",
    "\n",
    "canceled_month=canceled_month.reindex(['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'])\n",
    "\n",
    "booking_month['booking_percentage'] = (booking_month['is_canceled']/booking_month['is_canceled'].sum() )*100\n",
    "canceled_month['canceled_percentage'] = (canceled_month['is_canceled']/canceled_month['is_canceled'].sum() )*100\n",
    "\n",
    "booking_month.reset_index(level=0, inplace=True)\n",
    "canceled_month.reset_index(level=0, inplace=True)\n",
    "#booking_month['arrival_date_month'] = booking_month.index\n",
    "#canceled_month['arrival_date_month'] = canceled_month.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>booking_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>5929</td>\n",
       "      <td>4.966244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February</td>\n",
       "      <td>8068</td>\n",
       "      <td>6.757911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>March</td>\n",
       "      <td>9794</td>\n",
       "      <td>8.203642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April</td>\n",
       "      <td>11089</td>\n",
       "      <td>9.288359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May</td>\n",
       "      <td>11791</td>\n",
       "      <td>9.876367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>June</td>\n",
       "      <td>10939</td>\n",
       "      <td>9.162716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>July</td>\n",
       "      <td>12661</td>\n",
       "      <td>10.605096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>August</td>\n",
       "      <td>13873</td>\n",
       "      <td>11.620290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>September</td>\n",
       "      <td>10508</td>\n",
       "      <td>8.801702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>October</td>\n",
       "      <td>11160</td>\n",
       "      <td>9.347830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>November</td>\n",
       "      <td>6794</td>\n",
       "      <td>5.690785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>December</td>\n",
       "      <td>6780</td>\n",
       "      <td>5.679058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   arrival_date_month  is_canceled  booking_percentage\n",
       "0             January         5929            4.966244\n",
       "1            February         8068            6.757911\n",
       "2               March         9794            8.203642\n",
       "3               April        11089            9.288359\n",
       "4                 May        11791            9.876367\n",
       "5                June        10939            9.162716\n",
       "6                July        12661           10.605096\n",
       "7              August        13873           11.620290\n",
       "8           September        10508            8.801702\n",
       "9             October        11160            9.347830\n",
       "10           November         6794            5.690785\n",
       "11           December         6780            5.679058"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>canceled_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>1807</td>\n",
       "      <td>4.086386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February</td>\n",
       "      <td>2696</td>\n",
       "      <td>6.096789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>March</td>\n",
       "      <td>3149</td>\n",
       "      <td>7.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April</td>\n",
       "      <td>4524</td>\n",
       "      <td>10.230665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May</td>\n",
       "      <td>4677</td>\n",
       "      <td>10.576662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>June</td>\n",
       "      <td>4535</td>\n",
       "      <td>10.255540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>July</td>\n",
       "      <td>4742</td>\n",
       "      <td>10.723654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>August</td>\n",
       "      <td>5235</td>\n",
       "      <td>11.838535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>September</td>\n",
       "      <td>4116</td>\n",
       "      <td>9.308005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>October</td>\n",
       "      <td>4246</td>\n",
       "      <td>9.601990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>November</td>\n",
       "      <td>2122</td>\n",
       "      <td>4.798734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>December</td>\n",
       "      <td>2371</td>\n",
       "      <td>5.361827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   arrival_date_month  is_canceled  canceled_percentage\n",
       "0             January         1807             4.086386\n",
       "1            February         2696             6.096789\n",
       "2               March         3149             7.121212\n",
       "3               April         4524            10.230665\n",
       "4                 May         4677            10.576662\n",
       "5                June         4535            10.255540\n",
       "6                July         4742            10.723654\n",
       "7              August         5235            11.838535\n",
       "8           September         4116             9.308005\n",
       "9             October         4246             9.601990\n",
       "10           November         2122             4.798734\n",
       "11           December         2371             5.361827"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canceled_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.xticks(rotation=90)\n",
    "sns.lineplot(x = 'arrival_date_month',y='booking_percentage', data = booking_month,sort=False)\n",
    "sns.lineplot(x ='arrival_date_month',y='canceled_percentage', data = canceled_month,sort=False)\n",
    "plt.legend(labels=['Booking', 'Cancellation'])\n",
    "plt.title(\"Percentage of Booking/Cancellation per Month\", weight='bold')\n",
    "plt.xlabel('Arrival Month')\n",
    "plt.ylabel('Percentage of Reservation')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Lead Time Combined Histograms ')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make histogram\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 12))  # 3 Rows, 1 Col\n",
    "\n",
    "count0, bins_0, _ = ax[0].hist(df_booking.loc[(df_booking['is_canceled']==0),'lead_time'], bins=10, )\n",
    "count1, bins_1, _ = ax[1].hist(df_booking.loc[(df_booking['is_canceled']==1),'lead_time'], bins=10,)\n",
    "ax[2].plot((bins_0[:-1]+bins_0[1:])/2,count1/(count1 + count0));\n",
    "plt.title(\"Lead Time Combined Histograms \",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Adr Combined Histograms ')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make histogram\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 12))  # 3 Rows, 1 Col\n",
    "\n",
    "count0, bins_0, _ = ax[0].hist(df_booking.loc[(df_booking['is_canceled']==0),'adr'], bins=10)\n",
    "\n",
    "count1, bins_1, _ = ax[1].hist(df_booking.loc[(df_booking['is_canceled']==1),'adr'], bins=10)\n",
    "ax[2].plot((bins_0[:-1]+bins_0[1:])/2,count1/(count1 + count0));\n",
    "plt.title(\"Adr Combined Histograms \",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'market_segment', data = df_booking, hue = 'is_canceled',order = df_booking['market_segment'].value_counts().index)\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservation Status by Market Segment\", weight='bold')\n",
    "plt.xlabel('Market Segment')\n",
    "plt.ylabel('Number of Reservation')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'distribution_channel', data = df_booking, hue = 'is_canceled', order = df_booking['distribution_channel'].value_counts().index)\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservation Status by Distribution Channel\", weight='bold')\n",
    "plt.xlabel('Distribution Channel')\n",
    "plt.ylabel('Number of Reservation')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of Reservation')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "topcountries=df_booking['country'].value_counts().iloc[:10]\n",
    "sns.countplot(x='country', data=df_booking, \n",
    "              order=topcountries.index, palette=\"ch:s=.25,rot=-.25\")\n",
    "plt.title('Top Countries of Reservation', weight='bold')\n",
    "plt.xlabel('Country', fontsize=12)\n",
    "plt.ylabel('Number of Reservation', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'is_repeated_guest', data = df_booking, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservation Status by Type of Guest\", weight='bold')\n",
    "plt.xlabel('Type of Guest')\n",
    "plt.ylabel('Number of Reservation')\n",
    "plt.xticks([0,1],['New','Repeated'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'total_of_special_requests', data = df_booking, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservation Status by Number of Special Requests\", weight='bold')\n",
    "plt.xlabel('has Previous Cancellations')\n",
    "plt.ylabel('Number of Special Requests')\n",
    "plt.xticks()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=df_booking.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and display correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#sns.set_theme(style=\"white\",font_scale = 1)\n",
    "\n",
    "# Generate a large random dataset\n",
    "rs = np.random.RandomState(42)\n",
    "\n",
    "corr = d.corr()\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "cmap = sns.diverging_palette(230, 90, as_cmap=True)\n",
    "\n",
    "\n",
    "heat_plot =sns.heatmap(corr, cmap=cmap, vmin=-1, vmax=1, annot=True, center=0,\n",
    "             linewidths=1, )\n",
    "\n",
    "fig = heat_plot.get_figure()\n",
    "plt.title('Heatmap of Hotel Demand Dataset',fontsize = 25,weight='bold')\n",
    "plt.xticks(weight='bold',fontsize = 20,color='green')\n",
    "plt.yticks( weight='bold',fontsize = 20,color='green')\n",
    "plt.tight_layout() \n",
    "\n",
    "\n",
    "fig.savefig('heat_plot.jpg') \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stays_in_weekend_nights             0.178338\n",
       "children                            0.504779\n",
       "arrival_date_day_of_month           0.608413\n",
       "arrival_date_week_number            0.813199\n",
       "arrival_date_year                   1.673249\n",
       "stays_in_week_nights                2.477143\n",
       "babies                              3.248845\n",
       "adr                                 4.877698\n",
       "days_in_waiting_list                5.419315\n",
       "previous_bookings_not_canceled      5.735537\n",
       "adults                              5.999027\n",
       "is_repeated_guest                   8.478795\n",
       "previous_cancellations             11.014047\n",
       "agent                              12.823315\n",
       "booking_changes                    14.437057\n",
       "required_car_parking_spaces        19.549246\n",
       "total_of_special_requests          23.470590\n",
       "lead_time                          29.317738\n",
       "is_canceled                       100.000000\n",
       "Name: is_canceled, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = (d.corr()**2)**0.5\n",
    "cor_mat = cor[\"is_canceled\"].sort_values(ascending=True)\n",
    "cor_mat*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The heatmap reveals statistically significant correlations between the target variable and reservation_ status, lead_time, country, deposit_type. By checking reservation_ status values, it appears that it is highly correlated with the target and should be eliminated from further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_canceled', 'hotel', 'lead_time', 'arrival_date_year',\n",
       "       'arrival_date_month', 'arrival_date_week_number',\n",
       "       'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
       "       'stays_in_week_nights', 'adults', 'children', 'babies', 'meal',\n",
       "       'country', 'market_segment', 'distribution_channel',\n",
       "       'is_repeated_guest', 'previous_cancellations',\n",
       "       'previous_bookings_not_canceled', 'reserved_room_type',\n",
       "       'assigned_room_type', 'booking_changes', 'deposit_type', 'agent',\n",
       "       'days_in_waiting_list', 'customer_type', 'adr',\n",
       "       'required_car_parking_spaces', 'total_of_special_requests',\n",
       "       'reservation_status', 'reservation_status_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a new column which contain 1 if guest got the same room he/she booked\n",
    "d['got_required__room'] = 0\n",
    "d.loc[ d['reserved_room_type'] == d['assigned_room_type'] , 'got_required__room'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'got_required__room', data = d, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservations that Got the Required Room \", weight='bold')\n",
    "plt.xlabel('Got Required Room')\n",
    "plt.ylabel('Number of Reservations')\n",
    "plt.xticks([0,1],['NO','Yes'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['babies'] = np.where(d['babies']>= 1, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'babies', data = d, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservations with Babies\", weight='bold')\n",
    "plt.xlabel('With Babies')\n",
    "plt.ylabel('Number of Reservations')\n",
    "plt.xticks([0,1],['NO','Yes'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['children'] = np.where(d['children']>= 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'children', data = d, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservations with Children \", weight='bold')\n",
    "plt.xlabel('With Children')\n",
    "plt.ylabel('Number of Reservations')\n",
    "plt.xticks([0,1],['NO','Yes'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['previous_cancellations'] = np.where(d['previous_cancellations']>= 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'previous_cancellations', data = d, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservations that Has Previous Cancellations \", weight='bold')\n",
    "plt.xlabel('Has Previous Cancellations')\n",
    "plt.ylabel('Number of Reservations')\n",
    "plt.xticks([0,1],['NO','Yes'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['booking_changes'] = np.where(d['booking_changes']>= 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'booking_changes', data = d, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservations that Has booking changes \", weight='bold')\n",
    "plt.xlabel('Has booking_changes')\n",
    "plt.ylabel('Number of Reservations')\n",
    "plt.xticks([0,1],['NO','Yes'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "      <th>got_required__room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transient</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transient</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transient</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transient</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transient</td>\n",
       "      <td>98.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119385</th>\n",
       "      <td>Transient</td>\n",
       "      <td>96.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-09-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119386</th>\n",
       "      <td>Transient</td>\n",
       "      <td>225.43</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119387</th>\n",
       "      <td>Transient</td>\n",
       "      <td>157.71</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119388</th>\n",
       "      <td>Transient</td>\n",
       "      <td>104.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119389</th>\n",
       "      <td>Transient</td>\n",
       "      <td>151.20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119386 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_type     adr  required_car_parking_spaces  \\\n",
       "0          Transient    0.00                            0   \n",
       "1          Transient    0.00                            0   \n",
       "2          Transient   75.00                            0   \n",
       "3          Transient   75.00                            0   \n",
       "4          Transient   98.00                            0   \n",
       "...              ...     ...                          ...   \n",
       "119385     Transient   96.14                            0   \n",
       "119386     Transient  225.43                            0   \n",
       "119387     Transient  157.71                            0   \n",
       "119388     Transient  104.40                            0   \n",
       "119389     Transient  151.20                            0   \n",
       "\n",
       "        total_of_special_requests reservation_status reservation_status_date  \\\n",
       "0                               0          Check-Out              2015-07-01   \n",
       "1                               0          Check-Out              2015-07-01   \n",
       "2                               0          Check-Out              2015-07-02   \n",
       "3                               0          Check-Out              2015-07-02   \n",
       "4                               1          Check-Out              2015-07-03   \n",
       "...                           ...                ...                     ...   \n",
       "119385                          0          Check-Out              2017-09-06   \n",
       "119386                          2          Check-Out              2017-09-07   \n",
       "119387                          4          Check-Out              2017-09-07   \n",
       "119388                          0          Check-Out              2017-09-07   \n",
       "119389                          2          Check-Out              2017-09-07   \n",
       "\n",
       "        got_required__room  \n",
       "0                        1  \n",
       "1                        1  \n",
       "2                        0  \n",
       "3                        1  \n",
       "4                        1  \n",
       "...                    ...  \n",
       "119385                   1  \n",
       "119386                   1  \n",
       "119387                   1  \n",
       "119388                   1  \n",
       "119389                   1  \n",
       "\n",
       "[119386 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.iloc[:,25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['required_car_parking_spaces'] = np.where(d['required_car_parking_spaces']>= 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x = 'required_car_parking_spaces', data = d, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservations that Has  Required Car Parking Spaces \", weight='bold')\n",
    "plt.xlabel('Has Required Car Parking Spaces')\n",
    "plt.ylabel('Number of Reservations')\n",
    "plt.xticks([0,1],['NO','Yes'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['total_of_special_requests'] = np.where(d['total_of_special_requests']>= 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "sns.countplot(x = 'total_of_special_requests', data = d, hue = 'is_canceled')\n",
    "\n",
    "plt.legend(labels=['Confirmed', 'Canceled'])\n",
    "plt.title(\"Number of Reservations that Has Special Requests \", weight='bold')\n",
    "plt.xlabel('Has Special Requests')\n",
    "plt.ylabel('Number of Reservations')\n",
    "plt.xticks([0,1],['NO','Yes'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection based on correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since is_canceled is almost the same as reservation_status we will drop both reservation_status and reservation_status_date\n",
    "#df_booking.drop(['reservation_status'],axis=1,inplace=True)\n",
    "d.drop(['reservation_status','reservation_status_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we add got_required_room we can remove reserved_room_type, \n",
    "d.drop(['reserved_room_type','assigned_room_type'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.drop(['children','babies','meal','stays_in_weekend_nights','stays_in_week_nights'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.drop(['arrival_date_year','arrival_date_month','arrival_date_day_of_month','arrival_date_week_number'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119386, 23)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify split the data into 80% Training and 30% Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>adults</th>\n",
       "      <th>country</th>\n",
       "      <th>market_segment</th>\n",
       "      <th>distribution_channel</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_bookings_not_canceled</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>got_required__room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>236</td>\n",
       "      <td>2016</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Groups</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient-Party</td>\n",
       "      <td>48.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102208</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>November</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>IRL</td>\n",
       "      <td>Online TA</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>91.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24582</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>97</td>\n",
       "      <td>2016</td>\n",
       "      <td>May</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>CN</td>\n",
       "      <td>Online TA</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>66.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89383</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>28</td>\n",
       "      <td>2016</td>\n",
       "      <td>May</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient-Party</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47127</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>20</td>\n",
       "      <td>2016</td>\n",
       "      <td>February</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Online TA</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>86.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               hotel  lead_time  arrival_date_year arrival_date_month  \\\n",
       "5734    Resort Hotel        236               2016                May   \n",
       "102208    City Hotel          1               2016           November   \n",
       "24582   Resort Hotel         97               2016                May   \n",
       "89383     City Hotel         28               2016                May   \n",
       "47127     City Hotel         20               2016           February   \n",
       "\n",
       "        arrival_date_week_number  arrival_date_day_of_month  adults country  \\\n",
       "5734                          20                         12       2     PRT   \n",
       "102208                        48                         20       2     IRL   \n",
       "24582                         22                         22       2      CN   \n",
       "89383                         21                         19       2     PRT   \n",
       "47127                          7                          8       1     AGO   \n",
       "\n",
       "       market_segment distribution_channel  ...  \\\n",
       "5734           Groups                TA/TO  ...   \n",
       "102208      Online TA                TA/TO  ...   \n",
       "24582       Online TA                TA/TO  ...   \n",
       "89383       Corporate            Corporate  ...   \n",
       "47127       Online TA                TA/TO  ...   \n",
       "\n",
       "        previous_bookings_not_canceled  booking_changes  deposit_type  agent  \\\n",
       "5734                                 0                0    No Deposit    315   \n",
       "102208                               0                0    No Deposit      9   \n",
       "24582                                0                0    No Deposit    240   \n",
       "89383                                0                0    No Deposit    535   \n",
       "47127                                0                0    No Deposit      9   \n",
       "\n",
       "       days_in_waiting_list    customer_type     adr  \\\n",
       "5734                      0  Transient-Party   48.00   \n",
       "102208                    0        Transient   91.38   \n",
       "24582                     0        Transient   66.00   \n",
       "89383                     0  Transient-Party  100.00   \n",
       "47127                     0        Transient   86.00   \n",
       "\n",
       "       required_car_parking_spaces  total_of_special_requests  \\\n",
       "5734                             0                          0   \n",
       "102208                           0                          1   \n",
       "24582                            1                          1   \n",
       "89383                            0                          0   \n",
       "47127                            0                          1   \n",
       "\n",
       "        got_required__room  \n",
       "5734                     1  \n",
       "102208                   1  \n",
       "24582                    1  \n",
       "89383                    1  \n",
       "47127                    1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(d.iloc[:, 1:], d.iloc[:, 0], \n",
    "                                                    test_size = 0.2, random_state=42, stratify=d.iloc[:, 0])\n",
    "train_df = X_train.copy()\n",
    "train_df['is_canceled'] = y_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical features as numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lead_time', 'arrival_date_year', 'arrival_date_week_number', 'arrival_date_day_of_month', 'adults', 'is_repeated_guest', 'previous_cancellations', 'previous_bookings_not_canceled', 'booking_changes', 'agent', 'days_in_waiting_list', 'adr', 'required_car_parking_spaces', 'total_of_special_requests', 'got_required__room']\n",
      "['hotel', 'arrival_date_month', 'country', 'market_segment', 'distribution_channel', 'deposit_type', 'customer_type']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# numeric features\n",
    "numeric_features = X_train.select_dtypes(include='number').columns.tolist()\n",
    "print(numeric_features)\n",
    "\n",
    "# categorical features\n",
    "categorical_features = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "print(categorical_features)\n",
    "\n",
    "# build pipeline for numeric features\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scale', MinMaxScaler())])\n",
    "# build pipeline for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "    ('numeric', numeric_pipeline, numeric_features),\n",
    "    ('categorical', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "X_train_transformed=data_pipeline.fit_transform(X_train)\n",
    "X_test_transformed=data_pipeline.transform(X_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Fine tuning and Evaluation of models using  KFold CrossValidation¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine tune logistic regression Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision', 'recall', 'f1_macro']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   10.2s remaining:    6.8s\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80 F_macro , 0.81 Precision,  0.68 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.4s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "scores = cross_validate (lr, X_train_transformed, y_train, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:   47.6s remaining:   14.5s\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   51.6s finished\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1, param_grid={'C': [0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "random_grid = {'C':[.01,.1,1,10,100,1000,]}\n",
    "\n",
    "\n",
    "lr = LogisticRegression(random_state=42,n_jobs=-1)\n",
    "lr = GridSearchCV(estimator = lr, param_grid = random_grid, cv = 5, verbose=2,n_jobs = -1)# Fit the random search model\n",
    "lr.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   12.3s remaining:    8.2s\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80 F_macro , 0.81 Precision,  0.68 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.5s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
    "                                          fit_intercept=True,\n",
    "                                          intercept_scaling=1, l1_ratio=None,\n",
    "                                          max_iter=100, multi_class='auto',\n",
    "                                          n_jobs=-1, penalty='l2',\n",
    "                                          random_state=42, solver='lbfgs',\n",
    "                                          tol=0.0001, verbose=0,\n",
    "                                          warm_start=False)\n",
    "\n",
    "scores = cross_validate (lr, X_train_transformed, y_train, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.8232189973614775,Testing Accuracy:0.822388809783064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87     15034\n",
      "           1       0.81      0.68      0.74      8844\n",
      "\n",
      "    accuracy                           0.82     23878\n",
      "   macro avg       0.82      0.79      0.80     23878\n",
      "weighted avg       0.82      0.82      0.82     23878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr.fit(X_train_transformed, y_train)\n",
    "\n",
    "trainscore=lr.score(X_train_transformed, y_train)\n",
    "testscore=lr.score(X_test_transformed, y_test)\n",
    "print('Training Accuracy:{},Testing Accuracy:{}'.format(trainscore,testscore))\n",
    "ytest_predict = lr.predict(X_test_transformed) \n",
    "print(metrics.classification_report(y_test,ytest_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Fine Tuning of K Neighbors Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  2.5min remaining:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82 F_macro , 0.79 Precision,  0.76 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   8.2s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  17.5s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................................ C=100, total=  14.9s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   8.3s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  17.8s\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ........................................... C=1000, total=  14.8s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   9.1s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  17.7s\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ........................................... C=1000, total=  14.6s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   8.7s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=  18.7s\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ........................................... C=1000, total=  13.4s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   8.5s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=  19.5s\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ........................................... C=1000, total=  13.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=  17.6s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=  17.3s\n",
      "[CV] C=1000 ..........................................................\n",
      "[CV] ........................................... C=1000, total=   6.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=  18.1s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=  18.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=  18.5s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................................ C=100, total=  17.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.5min\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  17.7s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................................ C=100, total=  17.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.5min\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  17.4s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................................ C=100, total=  18.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.5min\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=  18.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................................ C=100, total=  18.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.5min\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=  18.0s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................................. C=10, total=  17.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 2.6min\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "scores = cross_validate (knn, X_train_transformed, y_train, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], 'p': [1, 2]}\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 33.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29],\n",
       "                                        'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9, 10, 11, 12, 13, 14,\n",
       "                                                        15, 16, 17, 18, 19, 20,\n",
       "                                                        21, 22, 23, 24, 25, 26,\n",
       "                                                        27, 28, 29],\n",
       "                                        'p': [1, 2]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "random_grid = {'leaf_size': list(range(1,30)),'n_neighbors': list(range(1,30)), 'p':[1,2]}\n",
    "print(random_grid)\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "knn= RandomizedSearchCV(estimator = knn, param_distributions = random_grid,  cv = 5, verbose=2,random_state=42, n_jobs = -1)# Fit the random search model\n",
    "knn.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(leaf_size=9, n_jobs=-1, n_neighbors=2, p=1)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.9min remaining:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82 F_macro , 0.87 Precision,  0.68 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=9, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=-1, n_neighbors=2, p=2,\n",
    "                     weights='uniform')\n",
    "\n",
    "scores = cross_validate (knn, X_train_transformed, y_train, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.9260690203961972,Testing Accuracy:0.8493173632632549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89     15034\n",
      "           1       0.87      0.69      0.77      8844\n",
      "\n",
      "    accuracy                           0.85     23878\n",
      "   macro avg       0.86      0.82      0.83     23878\n",
      "weighted avg       0.85      0.85      0.84     23878\n",
      "\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.7min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.8min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.8min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.8min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.8min\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train_transformed, y_train)\n",
    "\n",
    "trainscore=knn.score(X_train_transformed, y_train)\n",
    "testscore=knn.score(X_test_transformed, y_test)\n",
    "print('Training Accuracy:{},Testing Accuracy:{}'.format(trainscore,testscore))\n",
    "ytest_predict = knn.predict(X_test_transformed) \n",
    "print(metrics.classification_report(y_test,ytest_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training  of naive base Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    8.8s remaining:    5.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74 F_macro , 0.80 Precision,  0.54 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.2s finished\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "\n",
    "scores = cross_validate (nb, X_train_transformed, y_train, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.8s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=BernoulliNB(), n_jobs=-1, param_grid={}, verbose=2)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "random_grid = {}\n",
    "print(random_grid)\n",
    "\n",
    "nb = BernoulliNB()\n",
    "nb = GridSearchCV(estimator = nb, param_grid = random_grid,  cv = 5, verbose=2, n_jobs = -1)# Fit the random search model\n",
    "nb.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74 F_macro , 0.80 Precision,  0.54 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.9s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "\n",
    "scores = cross_validate(nb, X_train_transformed, y_train, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.7805524144574276,Testing Accuracy:0.7848228494848815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84     15034\n",
      "           1       0.82      0.54      0.65      8844\n",
      "\n",
      "    accuracy                           0.78     23878\n",
      "   macro avg       0.80      0.73      0.75     23878\n",
      "weighted avg       0.79      0.78      0.77     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb.fit(X_train_transformed, y_train)\n",
    "\n",
    "trainscore=nb.score(X_train_transformed, y_train)\n",
    "testscore=nb.score(X_test_transformed, y_test)\n",
    "print('Training Accuracy:{},Testing Accuracy:{}'.format(trainscore,testscore))\n",
    "ytest_predict = nb.predict(X_test_transformed) \n",
    "print(metrics.classification_report(y_test,ytest_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Fine Tuning of SVM  Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80 F_macro , 0.82 Precision,  0.67 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.6s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.6s finished\n"
     ]
    }
   ],
   "source": [
    "svm =  LinearSVC()\n",
    "scores = cross_validate (svm, X_train_transformed, y_train, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "random_grid = {'C': [0.1,1, 10, 100],'max_iter':[10,100,200,-1],'kernel':['linear','rbf']}\n",
    "\n",
    "svm =  LinearSVC()\n",
    "svm = RandomizedSearchCV(estimator = svm, param_distributions = random_grid,  cv = 5, verbose=2,random_state=42, n_jobs = -1)# Fit the random search model\n",
    "#svm.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................................*..*.\n",
      "optimization finished, #iter = 312\n",
      "Objective value = -36810.149058\n",
      "nSV = 51160\n",
      "..................****\n",
      "optimization finished, #iter = 353\n",
      "Objective value = -36741.790200\n",
      "nSV = 51036\n",
      "***\n",
      "optimization finished, #iter = 357\n",
      "Objective value = -36757.622481\n",
      "nSV = 51058\n",
      "\n",
      "optimization finished, #iter = 359\n",
      "Objective value = -36755.374811\n",
      "nSV = 51085\n",
      "*.*\n",
      "optimization finished, #iter = 362\n",
      "Objective value = -36652.834631\n",
      "nSV = 51009\n",
      "0.80 F_macro , 0.82 Precision,  0.67 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.7s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.8s finished\n"
     ]
    }
   ],
   "source": [
    "svm= LinearSVC(C=1.0,penalty='l2',max_iter=1000, random_state=42, verbose=2)\n",
    "\n",
    "scores = cross_validate (svm, X_train_transformed, y_train, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.8233969929220589,Testing Accuracy:0.8213418209230254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.87     15034\n",
      "           1       0.82      0.66      0.73      8844\n",
      "\n",
      "    accuracy                           0.82     23878\n",
      "   macro avg       0.82      0.79      0.80     23878\n",
      "weighted avg       0.82      0.82      0.82     23878\n",
      "\n",
      "[CV]  ................................................................\n",
      "[LibLinear][CV] ................................................. , total=   5.9s\n",
      "[CV]  ................................................................\n",
      "[LibLinear][CV] ................................................. , total=   5.6s\n",
      "[CV]  ................................................................\n",
      "[LibLinear][CV] ................................................. , total=   6.1s\n",
      "[CV]  ................................................................\n",
      "[LibLinear][CV] ................................................. , total=   6.0s\n",
      "[CV]  ................................................................\n",
      "[LibLinear][CV] ................................................. , total=   6.0s\n"
     ]
    }
   ],
   "source": [
    "svm.fit(X_train_transformed, y_train)\n",
    "trainscore=svm.score(X_train_transformed, y_train)\n",
    "testscore=svm.score(X_test_transformed, y_test)\n",
    "print('Training Accuracy:{},Testing Accuracy:{}'.format(trainscore,testscore))\n",
    "ytest_predict = svm.predict(X_test_transformed) \n",
    "print(metrics.classification_report(y_test,ytest_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Fine Tuning of Random Forest Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88 F_macro , 0.88 Precision,  0.81 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   26.9s remaining:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   27.0s finished\n"
     ]
    }
   ],
   "source": [
    "# fine tune random forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "scores = cross_validate (rf, X_train_transformed, y_train, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=None, random_state=42,n_jobs=-1)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, cv = 5, verbose=10,random_state=42, n_jobs = -1)# Fit the random search model\n",
    "#rf_random.fit(X_train_transformed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   25.6s remaining:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   25.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88 F_macro , 0.88 Precision,  0.81 Recall\n"
     ]
    }
   ],
   "source": [
    "# fine tune random forest model\n",
    "rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "\n",
    "scoring = ['precision', 'recall', 'f1_macro']\n",
    "scores = cross_validate (rf, X_train_transformed, y_train, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuned RF model has the best performance with an improvment of 8% over the Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation  on Holdout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.9955919922938392,Testing Accuracy:0.892202026970433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     15034\n",
      "           1       0.88      0.82      0.85      8844\n",
      "\n",
      "    accuracy                           0.89     23878\n",
      "   macro avg       0.89      0.88      0.88     23878\n",
      "weighted avg       0.89      0.89      0.89     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train_transformed, y_train)\n",
    "\n",
    "trainscore=rf.score(X_train_transformed, y_train)\n",
    "testscore=rf.score(X_test_transformed, y_test)\n",
    "print('Training Accuracy:{},Testing Accuracy:{}'.format(trainscore,testscore))\n",
    "ytest_predict = rf.predict(X_test_transformed) \n",
    "print(metrics.classification_report(y_test,ytest_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14039   995]\n",
      " [ 1579  7265]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/1358580074.py:2: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize = (8,6))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(51.0, 0.5, 'True Class')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    " \n",
    "cf_matrix = confusion_matrix(y_test,ytest_predict)\n",
    "print(cf_matrix)\n",
    "sns.heatmap(cf_matrix, annot=True,fmt='2d', cmap='Greens')\n",
    "plt.xlabel('Predicted Class',weight='bold')\n",
    "plt.ylabel('True Class',weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.500\n",
      "Logistic: ROC AUC=0.958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Roc Curve of Random Forest')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set_palette(\"ch:s=.25,rot=-.25\")\n",
    "plt.figure(figsize = (8,6))\n",
    "rf_probs = rf.predict_proba(X_test_transformed)\n",
    "# keep probabilities for the positive outcome only\n",
    "rf_probs = rf_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (rf_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill',color='green')\n",
    "pyplot.plot(rf_fpr, rf_tpr, marker='.', label='Random Forest',color='green',)\n",
    "plt.legend(labels=['No Skill:{:.2f}'.format(ns_auc), 'Random Forest: {:.2f}'.format(rf_auc)])\n",
    "plt.title('Roc Curve of Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "y_score = rf.predict_proba(X_test_transformed)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "\n",
    "# The histogram of scores compared to true labels\n",
    "fig_hist = px.histogram(\n",
    "    x=y_score, color=y_test, nbins=50,\n",
    "    labels=dict(color='True Labels', x='Score')\n",
    ")\n",
    "\n",
    "fig_hist.show()\n",
    "\n",
    "\n",
    "# Evaluating model performance at various thresholds\n",
    "df = pd.DataFrame({\n",
    "    'False Positive Rate': fpr,\n",
    "    'True Positive Rate': tpr\n",
    "}, index=thresholds)\n",
    "df.index.name = \"Thresholds\"\n",
    "df.columns.name = \"Rate\"\n",
    "\n",
    "fig_thresh = px.line(\n",
    "    df, title='TPR and FPR at every threshold',\n",
    "    width=700, height=500\n",
    ")\n",
    "\n",
    "fig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig_thresh.update_xaxes(range=[0, 1], constrain='domain')\n",
    "fig_thresh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "### handling imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RandomForestClassifier(X_train_smote, y_train_smote,X_test, y_test):\n",
    "    \n",
    "\n",
    "    lr_cor = LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
    "                                              fit_intercept=True,\n",
    "                                              intercept_scaling=1, l1_ratio=None,\n",
    "                                              max_iter=100, multi_class='auto',\n",
    "                                              n_jobs=-1, penalty='l2',\n",
    "                                              random_state=42, solver='lbfgs',\n",
    "                                              tol=0.0001, verbose=0,\n",
    "                                              warm_start=False)\n",
    "\n",
    "    scores = cross_validate (lr_cor, X_train_smote, y_train_smote, cv=5,scoring=scoring, verbose=2,n_jobs = -1)\n",
    "    print(\"%0.2f F_macro , %0.2f Precision,  %0.2f Recall\" % (scores['test_f1_macro'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean()))\n",
    "\n",
    "    lr_cor.fit( X_train_smote, y_train_smote)\n",
    "\n",
    "    trainscore=lr_cor.score(X_train_smote, y_train_smote)\n",
    "    testscore=lr_cor.score(X_test, y_test)\n",
    "    print('Training Accuracy:{},Testing Accuracy:{}'.format(trainscore,testscore))\n",
    "    ytest_predict = lr_cor.predict(X_test) \n",
    "    print(metrics.classification_report(y_test,ytest_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "### with Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/imblearn/utils/_validation.py:318: UserWarning:\n",
      "\n",
      "After over-sampling, the number of samples (70752) in class 1 will be larger than the number of samples in the majority class (class #0 -> 60132)\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    8.3s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81 F_macro , 0.83 Precision,  0.83 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.8151645732098652,Testing Accuracy:0.8097411843537985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84     15034\n",
      "           1       0.71      0.82      0.76      8844\n",
      "\n",
      "    accuracy                           0.81     23878\n",
      "   macro avg       0.80      0.81      0.80     23878\n",
      "weighted avg       0.82      0.81      0.81     23878\n",
      "\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   7.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   7.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   5.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   7.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   6.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   4.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   8.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   7.7s\n"
     ]
    }
   ],
   "source": [
    "import imblearn.over_sampling\n",
    "# setup for the ratio argument of RandomOverSampler initialization\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "ratio = {1 : n_pos * 2, 0 : n_neg} \n",
    "\n",
    "# randomly oversample positive samples: create 4x as many \n",
    "ROS = imblearn.over_sampling.RandomOverSampler(sampling_strategy = ratio, random_state=42) \n",
    "X_train_resampled, y_train_resampled = ROS.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "train_RandomForestClassifier(X_train_resampled, y_train_resampled,X_test_transformed, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over sampling harm Random forest performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "### with under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    4.5s remaining:    3.0s\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81 F_macro , 0.82 Precision,  0.79 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.8122031886024423,Testing Accuracy:0.8167350699388558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85     15034\n",
      "           1       0.73      0.79      0.76      8844\n",
      "\n",
      "    accuracy                           0.82     23878\n",
      "   macro avg       0.80      0.81      0.81     23878\n",
      "weighted avg       0.82      0.82      0.82     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X_under, y_under = RandomUnderSampler(random_state=42).fit_sample(X_train_transformed,y_train)\n",
    "train_RandomForestClassifier(X_under, y_under,X_test_transformed, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under sampling harm Random forest performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/imblearn/utils/_validation.py:318: UserWarning:\n",
      "\n",
      "After over-sampling, the number of samples (70752) in class 1 will be larger than the number of samples in the majority class (class #0 -> 60132)\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    8.6s remaining:    5.7s\n",
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82 F_macro , 0.83 Precision,  0.83 Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safa/anaconda3/envs/metis/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.8173573546040769,Testing Accuracy:0.8097830639082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84     15034\n",
      "           1       0.71      0.82      0.76      8844\n",
      "\n",
      "    accuracy                           0.81     23878\n",
      "   macro avg       0.80      0.81      0.80     23878\n",
      "weighted avg       0.82      0.81      0.81     23878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote = imblearn.over_sampling.SMOTE(sampling_strategy=ratio, random_state = 42)\n",
    "    \n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "train_RandomForestClassifier(X_train_smote, y_train_smote,X_test_transformed, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOT sampling harm Random forest performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = setup(train_df, target = 'is_canceled', train_size = 0.99,session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#best = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
